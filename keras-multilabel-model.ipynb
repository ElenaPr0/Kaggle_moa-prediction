{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:46.693240Z",
     "iopub.status.busy": "2020-10-15T08:21:46.692120Z",
     "iopub.status.idle": "2020-10-15T08:21:47.751647Z",
     "shell.execute_reply": "2020-10-15T08:21:47.750858Z"
    },
    "papermill": {
     "duration": 1.08074,
     "end_time": "2020-10-15T08:21:47.751765",
     "exception": false,
     "start_time": "2020-10-15T08:21:46.671025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:47.794484Z",
     "iopub.status.busy": "2020-10-15T08:21:47.793780Z",
     "iopub.status.idle": "2020-10-15T08:21:53.601070Z",
     "shell.execute_reply": "2020-10-15T08:21:53.601761Z"
    },
    "papermill": {
     "duration": 5.832408,
     "end_time": "2020-10-15T08:21:53.601953",
     "exception": false,
     "start_time": "2020-10-15T08:21:47.769545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses, backend\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:53.647883Z",
     "iopub.status.busy": "2020-10-15T08:21:53.646950Z",
     "iopub.status.idle": "2020-10-15T08:21:58.831250Z",
     "shell.execute_reply": "2020-10-15T08:21:58.830121Z"
    },
    "papermill": {
     "duration": 5.210314,
     "end_time": "2020-10-15T08:21:58.831382",
     "exception": false,
     "start_time": "2020-10-15T08:21:53.621068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "\n",
    "ss = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:58.872438Z",
     "iopub.status.busy": "2020-10-15T08:21:58.871830Z",
     "iopub.status.idle": "2020-10-15T08:21:58.953234Z",
     "shell.execute_reply": "2020-10-15T08:21:58.953936Z"
    },
    "papermill": {
     "duration": 0.104147,
     "end_time": "2020-10-15T08:21:58.954095",
     "exception": false,
     "start_time": "2020-10-15T08:21:58.849948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23814 entries, 0 to 23813\n",
      "Columns: 876 entries, sig_id to c-99\n",
      "dtypes: float64(872), int64(1), object(3)\n",
      "memory usage: 159.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.info()\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.026053Z",
     "iopub.status.busy": "2020-10-15T08:21:59.016039Z",
     "iopub.status.idle": "2020-10-15T08:21:59.066926Z",
     "shell.execute_reply": "2020-10-15T08:21:59.066421Z"
    },
    "papermill": {
     "duration": 0.092577,
     "end_time": "2020-10-15T08:21:59.067026",
     "exception": false,
     "start_time": "2020-10-15T08:21:58.974449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3982 entries, 0 to 3981\n",
      "Columns: 876 entries, sig_id to c-99\n",
      "dtypes: float64(872), int64(1), object(3)\n",
      "memory usage: 26.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303 -0.1193   \n",
       "1 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690 -0.5382   \n",
       "2 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530 -1.0140   \n",
       "3 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325 -0.9005   \n",
       "4 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742  1.0900   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2  0.8662  1.0160  0.4924 -0.1942  \n",
       "3  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4 -0.2962 -0.5313  0.9931  1.8380  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.info()\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.137467Z",
     "iopub.status.busy": "2020-10-15T08:21:59.118460Z",
     "iopub.status.idle": "2020-10-15T08:21:59.144404Z",
     "shell.execute_reply": "2020-10-15T08:21:59.143765Z"
    },
    "papermill": {
     "duration": 0.05689,
     "end_time": "2020-10-15T08:21:59.144525",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.087635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23814 entries, 0 to 23813\n",
      "Columns: 207 entries, sig_id to wnt_inhibitor\n",
      "dtypes: int64(206), object(1)\n",
      "memory usage: 37.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.info()\n",
    "train_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.215981Z",
     "iopub.status.busy": "2020-10-15T08:21:59.214810Z",
     "iopub.status.idle": "2020-10-15T08:21:59.309740Z",
     "shell.execute_reply": "2020-10-15T08:21:59.309019Z"
    },
    "papermill": {
     "duration": 0.140449,
     "end_time": "2020-10-15T08:21:59.309937",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.169488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 875)\n",
      "(23814, 206)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    #df = df.drop(not_imp_features, axis=1)\n",
    "    return df\n",
    "\n",
    "train = preprocess(train_features)\n",
    "test = preprocess(test_features)\n",
    "\n",
    "#train = train.loc[train_features['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "#train_targets = train_targets.loc[train_features['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "del train_targets['sig_id']\n",
    "\n",
    "print(train.shape)\n",
    "print(train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.364978Z",
     "iopub.status.busy": "2020-10-15T08:21:59.363985Z",
     "iopub.status.idle": "2020-10-15T08:21:59.619729Z",
     "shell.execute_reply": "2020-10-15T08:21:59.619217Z"
    },
    "papermill": {
     "duration": 0.286997,
     "end_time": "2020-10-15T08:21:59.619860",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.332863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_columns = train.columns.to_list()\n",
    "g_list = [i for i in train_columns if i.startswith('g-')]\n",
    "c_list = [i for i in train_columns if i.startswith('c-')]\n",
    "\n",
    "train['mean_g-'] = train[g_list].mean(axis=1)\n",
    "train['mean_c-'] = train[c_list].mean(axis=1)\n",
    "\n",
    "test['mean_g-'] = test[g_list].mean(axis=1)\n",
    "test['mean_c-'] = test[c_list].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021723,
     "end_time": "2020-10-15T08:21:59.663672",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.641949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The importance features were received via the ExtraTreesClassifier model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.712389Z",
     "iopub.status.busy": "2020-10-15T08:21:59.711759Z",
     "iopub.status.idle": "2020-10-15T08:21:59.717341Z",
     "shell.execute_reply": "2020-10-15T08:21:59.716888Z"
    },
    "papermill": {
     "duration": 0.031765,
     "end_time": "2020-10-15T08:21:59.717434",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.685669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Feature Importance with Extra Trees Classifier\\nfrom sklearn.ensemble import ExtraTreesClassifier\\n\\nX = train.copy()\\n#X_val = features_valid.copy()\\nY = train_targets.copy()\\n#Y_val = target_valid.copy()\\n\\nmodel = ExtraTreesClassifier(n_jobs=-1, random_state=42, verbose=2, n_estimators=300, max_depth=11)\\n\\nmodel.fit(X, Y)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "X = train.copy()\n",
    "#X_val = features_valid.copy()\n",
    "Y = train_targets.copy()\n",
    "#Y_val = target_valid.copy()\n",
    "\n",
    "model = ExtraTreesClassifier(n_jobs=-1, random_state=42, verbose=2, n_estimators=300, max_depth=11)\n",
    "\n",
    "model.fit(X, Y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.765856Z",
     "iopub.status.busy": "2020-10-15T08:21:59.765233Z",
     "iopub.status.idle": "2020-10-15T08:21:59.771232Z",
     "shell.execute_reply": "2020-10-15T08:21:59.771655Z"
    },
    "papermill": {
     "duration": 0.03212,
     "end_time": "2020-10-15T08:21:59.771768",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.739648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'features=X.columns\\nimportances = model.feature_importances_\\nindices = np.argsort(importances)\\nimportances[indices]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''features=X.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "importances[indices]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.821602Z",
     "iopub.status.busy": "2020-10-15T08:21:59.821042Z",
     "iopub.status.idle": "2020-10-15T08:21:59.826911Z",
     "shell.execute_reply": "2020-10-15T08:21:59.826351Z"
    },
    "papermill": {
     "duration": 0.032125,
     "end_time": "2020-10-15T08:21:59.827035",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.794910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Notimportant features\\nnotimportant_features_trees = features[indices[importances[indices]<0.00022]] \\nprint(list(notimportant_features_trees))\\nprint(len(notimportant_features_trees))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Notimportant features\n",
    "notimportant_features_trees = features[indices[importances[indices]<0.00022]] \n",
    "print(list(notimportant_features_trees))\n",
    "print(len(notimportant_features_trees))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023065,
     "end_time": "2020-10-15T08:21:59.873414",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.850349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here is a list of notimportant features that we can drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.934157Z",
     "iopub.status.busy": "2020-10-15T08:21:59.933418Z",
     "iopub.status.idle": "2020-10-15T08:21:59.936843Z",
     "shell.execute_reply": "2020-10-15T08:21:59.937297Z"
    },
    "papermill": {
     "duration": 0.04049,
     "end_time": "2020-10-15T08:21:59.937397",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.896907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "not_imp_features = ['g-247', 'g-104', 'g-234', 'g-707', 'g-571', 'g-54', 'g-375', 'g-413', 'g-227', 'g-88', \n",
    "                    'g-341', 'g-519', 'g-45', 'g-573', 'g-549', 'g-172', 'g-438', 'g-555', 'g-232', 'g-536', \n",
    "                    'g-756', 'g-430', 'g-592', 'g-721', 'g-452', 'g-605', 'g-302', 'g-56', 'g-32', 'g-582', \n",
    "                    'g-219', 'g-109', 'g-713', 'g-358', 'g-717', 'g-376', 'g-607', 'g-101', 'g-370', 'mean_g-', \n",
    "                    'g-114', 'g-191', 'g-755', 'g-196', 'g-326', 'g-484', 'g-754', 'g-44', 'g-747', 'g-76', \n",
    "                    'g-401', 'g-223', 'g-286', 'g-86', 'g-653', 'g-111', 'g-654', 'g-513', 'g-531', 'g-2', \n",
    "                    'g-550', 'g-611', 'g-725', 'g-340', 'g-276', 'g-346', 'g-710', 'g-650', 'g-530', 'g-748', \n",
    "                    'g-532', 'g-581', 'g-24', 'g-719', 'g-331', 'g-682', 'g-739', 'g-244', 'g-82', 'g-5', \n",
    "                    'g-687', 'g-737', 'g-161', 'g-399', 'g-425', 'g-545', 'g-103', 'g-645', 'g-473', 'g-740', \n",
    "                    'g-15', 'g-681', 'g-362', 'g-483', 'g-676', 'g-612', 'g-238', 'g-585', 'g-184', 'g-680', \n",
    "                    'g-580']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:21:59.992238Z",
     "iopub.status.busy": "2020-10-15T08:21:59.990933Z",
     "iopub.status.idle": "2020-10-15T08:22:00.175957Z",
     "shell.execute_reply": "2020-10-15T08:22:00.175421Z"
    },
    "papermill": {
     "duration": 0.21463,
     "end_time": "2020-10-15T08:22:00.176076",
     "exception": false,
     "start_time": "2020-10-15T08:21:59.961446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop(not_imp_features, axis=1)\n",
    "test = test.drop(not_imp_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:22:00.230147Z",
     "iopub.status.busy": "2020-10-15T08:22:00.229314Z",
     "iopub.status.idle": "2020-10-15T08:22:00.234069Z",
     "shell.execute_reply": "2020-10-15T08:22:00.233545Z"
    },
    "papermill": {
     "duration": 0.033535,
     "end_time": "2020-10-15T08:22:00.234163",
     "exception": false,
     "start_time": "2020-10-15T08:22:00.200628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 776)\n",
      "(3982, 776)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:22:00.315831Z",
     "iopub.status.busy": "2020-10-15T08:22:00.314649Z",
     "iopub.status.idle": "2020-10-15T08:22:07.008824Z",
     "shell.execute_reply": "2020-10-15T08:22:07.008007Z"
    },
    "papermill": {
     "duration": 6.737928,
     "end_time": "2020-10-15T08:22:07.008941",
     "exception": false,
     "start_time": "2020-10-15T08:22:00.271013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "num_columns = train.columns\n",
    "train[num_columns] = scaler.fit_transform(train[num_columns])\n",
    "test[num_columns] = scaler.transform(test[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:22:07.070863Z",
     "iopub.status.busy": "2020-10-15T08:22:07.070106Z",
     "iopub.status.idle": "2020-10-15T08:22:07.073145Z",
     "shell.execute_reply": "2020-10-15T08:22:07.072651Z"
    },
    "papermill": {
     "duration": 0.038818,
     "end_time": "2020-10-15T08:22:07.073243",
     "exception": false,
     "start_time": "2020-10-15T08:22:07.034425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(num_columns):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(num_columns),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1024, activation=\"relu\")),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25), \n",
    "    tfa.layers.WeightNormalization(tf.keras.layers.Dense(512, activation=\"relu\")),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation=\"sigmoid\"))\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=logloss\n",
    "                  )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:22:07.127847Z",
     "iopub.status.busy": "2020-10-15T08:22:07.126985Z",
     "iopub.status.idle": "2020-10-15T08:22:07.130873Z",
     "shell.execute_reply": "2020-10-15T08:22:07.130393Z"
    },
    "papermill": {
     "duration": 0.032649,
     "end_time": "2020-10-15T08:22:07.130971",
     "exception": false,
     "start_time": "2020-10-15T08:22:07.098322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:22:07.190457Z",
     "iopub.status.busy": "2020-10-15T08:22:07.189732Z",
     "iopub.status.idle": "2020-10-15T08:22:07.192783Z",
     "shell.execute_reply": "2020-10-15T08:22:07.192328Z"
    },
    "papermill": {
     "duration": 0.036543,
     "end_time": "2020-10-15T08:22:07.192894",
     "exception": false,
     "start_time": "2020-10-15T08:22:07.156351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for _target in train_targets.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "# Evaluation Metric with clipping and no label smoothing\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n",
    "    return -backend.mean(y_true*backend.log(y_pred) + (1-y_true)*backend.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:22:07.260662Z",
     "iopub.status.busy": "2020-10-15T08:22:07.251606Z",
     "iopub.status.idle": "2020-10-15T08:49:02.535060Z",
     "shell.execute_reply": "2020-10-15T08:49:02.534392Z"
    },
    "papermill": {
     "duration": 1615.316717,
     "end_time": "2020-10-15T08:49:02.535170",
     "exception": false,
     "start_time": "2020-10-15T08:22:07.218453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 23, Fold 0\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5741 - logloss: 0.5715 - val_loss: 0.2624 - val_logloss: 0.2624\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1103 - logloss: 0.1098 - val_loss: 0.0451 - val_logloss: 0.0451\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0363 - logloss: 0.0362 - val_loss: 0.0283 - val_logloss: 0.0283\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0260 - logloss: 0.0259 - val_loss: 0.0227 - val_logloss: 0.0227\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0227 - logloss: 0.0226 - val_loss: 0.0214 - val_logloss: 0.0213\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0196 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0194 - logloss: 0.0194 - val_loss: 0.0187 - val_logloss: 0.0186\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0185 - logloss: 0.0185 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0181 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0169 - val_loss: 0.0166 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0167 - val_logloss: 0.0163\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0145 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "\n",
      "Seed 23, Fold 1\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5740 - logloss: 0.5713 - val_loss: 0.2467 - val_logloss: 0.2468\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1113 - logloss: 0.1107 - val_loss: 0.0467 - val_logloss: 0.0467\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0282 - val_logloss: 0.0282\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0260 - logloss: 0.0259 - val_loss: 0.0225 - val_logloss: 0.0225\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0205 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0191 - val_logloss: 0.0192\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0186 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0191 - logloss: 0.0190 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0176 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 23, Fold 2\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5752 - logloss: 0.5726 - val_loss: 0.2371 - val_logloss: 0.2371\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1112 - logloss: 0.1106 - val_loss: 0.0461 - val_logloss: 0.0461\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0363 - logloss: 0.0362 - val_loss: 0.0287 - val_logloss: 0.0287\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0259 - logloss: 0.0258 - val_loss: 0.0230 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0224 - val_loss: 0.0206 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0195 - val_logloss: 0.0195\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0186 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0186 - logloss: 0.0186 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0175 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0169 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0160 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0142 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 23, Fold 3\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5697 - logloss: 0.5669 - val_loss: 0.2372 - val_logloss: 0.2372\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1090 - logloss: 0.1086 - val_loss: 0.0444 - val_logloss: 0.0443\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0362 - logloss: 0.0360 - val_loss: 0.0286 - val_logloss: 0.0286\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0259 - logloss: 0.0261 - val_loss: 0.0234 - val_logloss: 0.0233\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0228 - logloss: 0.0227 - val_loss: 0.0204 - val_logloss: 0.0203\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0190 - val_logloss: 0.0190\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0196 - val_loss: 0.0183 - val_logloss: 0.0183\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0190 - logloss: 0.0189 - val_loss: 0.0177 - val_logloss: 0.0177\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0174 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0163 - val_logloss: 0.0163\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0162 - val_logloss: 0.0162\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0158 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0153 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 24/35\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "\n",
      "Seed 23, Fold 4\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5738 - logloss: 0.5710 - val_loss: 0.2559 - val_logloss: 0.2559\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1102 - logloss: 0.1096 - val_loss: 0.0487 - val_logloss: 0.0487\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0366 - logloss: 0.0364 - val_loss: 0.0277 - val_logloss: 0.0277\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0257 - logloss: 0.0256 - val_loss: 0.0232 - val_logloss: 0.0232\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0221 - logloss: 0.0220 - val_loss: 0.0206 - val_logloss: 0.0206\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0208 - logloss: 0.0207 - val_loss: 0.0197 - val_logloss: 0.0196\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0195 - logloss: 0.0194 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0180 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0177 - val_logloss: 0.0176\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0171 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0171 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0163 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0162 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0131 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0130 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0130 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "\n",
      "Seed 23, Fold 5\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5744 - logloss: 0.5717 - val_loss: 0.2437 - val_logloss: 0.2437\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1111 - logloss: 0.1105 - val_loss: 0.0464 - val_logloss: 0.0464\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0273 - val_logloss: 0.0273\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0257 - logloss: 0.0256 - val_loss: 0.0228 - val_logloss: 0.0228\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0222 - logloss: 0.0222 - val_loss: 0.0205 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0192 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0183 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0186 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0170 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0175 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0146 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0130 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0127 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 23, Fold 6\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5728 - logloss: 0.5703 - val_loss: 0.2503 - val_logloss: 0.2503\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1101 - logloss: 0.1095 - val_loss: 0.0473 - val_logloss: 0.0473\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0269 - val_logloss: 0.0269\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0259 - logloss: 0.0258 - val_loss: 0.0231 - val_logloss: 0.0231\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0209 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0194 - logloss: 0.0193 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0189 - val_loss: 0.0179 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0174 - val_logloss: 0.0175\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0169 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0167 - val_logloss: 0.0168\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0171 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0165 - val_loss: 0.0161 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 2s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0150 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0147 - val_loss: 0.0155 - val_logloss: 0.0158\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0141 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "\n",
      "Seed 62, Fold 0\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5773 - logloss: 0.5745 - val_loss: 0.2694 - val_logloss: 0.2694\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1107 - logloss: 0.1101 - val_loss: 0.0469 - val_logloss: 0.0469\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0365 - logloss: 0.0364 - val_loss: 0.0286 - val_logloss: 0.0286\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0256 - logloss: 0.0255 - val_loss: 0.0222 - val_logloss: 0.0222\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0231 - logloss: 0.0229 - val_loss: 0.0207 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0208 - logloss: 0.0207 - val_loss: 0.0192 - val_logloss: 0.0192\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0197 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0188 - val_loss: 0.0176 - val_logloss: 0.0176\n",
      "Epoch 9/35\n",
      "107/107 - 2s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0169 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0175 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0173 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0162 - val_logloss: 0.0162\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0152 - val_logloss: 0.0153\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "\n",
      "Seed 62, Fold 1\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5747 - logloss: 0.5722 - val_loss: 0.2565 - val_logloss: 0.2565\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1119 - logloss: 0.1113 - val_loss: 0.0440 - val_logloss: 0.0440\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0370 - logloss: 0.0370 - val_loss: 0.0274 - val_logloss: 0.0274\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0262 - val_loss: 0.0234 - val_logloss: 0.0234\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0207 - val_logloss: 0.0208\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0199 - logloss: 0.0198 - val_loss: 0.0192 - val_logloss: 0.0192\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0190 - logloss: 0.0189 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0173 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0169 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0175 - val_loss: 0.0173 - val_logloss: 0.0172\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0168 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0154 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0141 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0131 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 62, Fold 2\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5773 - logloss: 0.5747 - val_loss: 0.2563 - val_logloss: 0.2563\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1116 - logloss: 0.1110 - val_loss: 0.0478 - val_logloss: 0.0478\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0363 - logloss: 0.0361 - val_loss: 0.0288 - val_logloss: 0.0288\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0262 - logloss: 0.0260 - val_loss: 0.0230 - val_logloss: 0.0230\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0209 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0205 - logloss: 0.0205 - val_loss: 0.0201 - val_logloss: 0.0200\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0196 - val_loss: 0.0188 - val_logloss: 0.0188\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0175 - val_logloss: 0.0175\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0167 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 62, Fold 3\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5693 - logloss: 0.5668 - val_loss: 0.2474 - val_logloss: 0.2474\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1106 - logloss: 0.1100 - val_loss: 0.0454 - val_logloss: 0.0454\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0366 - logloss: 0.0365 - val_loss: 0.0290 - val_logloss: 0.0290\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0261 - val_loss: 0.0224 - val_logloss: 0.0225\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0206 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0206 - val_loss: 0.0192 - val_logloss: 0.0192\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0194 - logloss: 0.0193 - val_loss: 0.0186 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0185 - logloss: 0.0185 - val_loss: 0.0177 - val_logloss: 0.0177\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0166 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0168 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 62, Fold 4\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5752 - logloss: 0.5727 - val_loss: 0.2473 - val_logloss: 0.2472\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1104 - logloss: 0.1099 - val_loss: 0.0458 - val_logloss: 0.0458\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0276 - val_logloss: 0.0276\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0261 - logloss: 0.0260 - val_loss: 0.0225 - val_logloss: 0.0225\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0222 - logloss: 0.0221 - val_loss: 0.0207 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0194 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0178 - logloss: 0.0178 - val_loss: 0.0171 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0131 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 62, Fold 5\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5718 - logloss: 0.5694 - val_loss: 0.2633 - val_logloss: 0.2633\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1118 - logloss: 0.1112 - val_loss: 0.0479 - val_logloss: 0.0478\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0362 - logloss: 0.0361 - val_loss: 0.0277 - val_logloss: 0.0277\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0265 - logloss: 0.0264 - val_loss: 0.0233 - val_logloss: 0.0232\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0223 - val_loss: 0.0206 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0207 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0197 - val_loss: 0.0195 - val_logloss: 0.0194\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0189 - val_loss: 0.0181 - val_logloss: 0.0181\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0173 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0166 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0164 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 20/35\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "\n",
      "Seed 62, Fold 6\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5756 - logloss: 0.5732 - val_loss: 0.2467 - val_logloss: 0.2467\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1117 - logloss: 0.1112 - val_loss: 0.0469 - val_logloss: 0.0469\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0279 - val_logloss: 0.0279\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0262 - logloss: 0.0261 - val_loss: 0.0233 - val_logloss: 0.0233\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0211 - val_logloss: 0.0211\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0208 - logloss: 0.0207 - val_loss: 0.0195 - val_logloss: 0.0195\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0188 - val_logloss: 0.0187\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0186 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0176 - val_logloss: 0.0175\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0170 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0170 - val_logloss: 0.0171\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0165 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0150 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0130 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0126 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0126 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 107, Fold 0\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5731 - logloss: 0.5703 - val_loss: 0.2814 - val_logloss: 0.2814\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1119 - logloss: 0.1113 - val_loss: 0.0486 - val_logloss: 0.0486\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0368 - logloss: 0.0367 - val_loss: 0.0279 - val_logloss: 0.0279\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0260 - logloss: 0.0259 - val_loss: 0.0226 - val_logloss: 0.0226\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0228 - logloss: 0.0227 - val_loss: 0.0207 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0212 - logloss: 0.0210 - val_loss: 0.0196 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0186 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0191 - logloss: 0.0190 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0175 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0158 - val_logloss: 0.0158\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0121 - logloss: 0.0125 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0121 - logloss: 0.0125 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0125 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 107, Fold 1\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5714 - logloss: 0.5687 - val_loss: 0.2759 - val_logloss: 0.2759\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1111 - logloss: 0.1105 - val_loss: 0.0512 - val_logloss: 0.0512\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0368 - logloss: 0.0367 - val_loss: 0.0284 - val_logloss: 0.0284\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0260 - logloss: 0.0259 - val_loss: 0.0236 - val_logloss: 0.0236\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0211 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0204 - val_logloss: 0.0201\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0188 - val_logloss: 0.0187\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0186 - val_loss: 0.0181 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0177 - val_logloss: 0.0176\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0161 - val_logloss: 0.0163\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0163 - val_logloss: 0.0162\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 24/35\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0139 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "\n",
      "Seed 107, Fold 2\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5729 - logloss: 0.5705 - val_loss: 0.2651 - val_logloss: 0.2651\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1105 - logloss: 0.1100 - val_loss: 0.0518 - val_logloss: 0.0518\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0362 - logloss: 0.0361 - val_loss: 0.0278 - val_logloss: 0.0278\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0260 - logloss: 0.0258 - val_loss: 0.0233 - val_logloss: 0.0234\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0223 - val_loss: 0.0205 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0213 - logloss: 0.0211 - val_loss: 0.0197 - val_logloss: 0.0196\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0182 - val_logloss: 0.0182\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0190 - logloss: 0.0189 - val_loss: 0.0177 - val_logloss: 0.0177\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0164 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0121 - logloss: 0.0125 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0121 - logloss: 0.0125 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0121 - logloss: 0.0124 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0120 - logloss: 0.0125 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 107, Fold 3\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5752 - logloss: 0.5726 - val_loss: 0.2726 - val_logloss: 0.2726\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1100 - logloss: 0.1095 - val_loss: 0.0470 - val_logloss: 0.0470\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0364 - logloss: 0.0363 - val_loss: 0.0287 - val_logloss: 0.0287\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0260 - logloss: 0.0259 - val_loss: 0.0235 - val_logloss: 0.0235\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0208 - val_logloss: 0.0208\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0211 - logloss: 0.0210 - val_loss: 0.0198 - val_logloss: 0.0198\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0188 - val_loss: 0.0181 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0181 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0171 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0165 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0155 - val_logloss: 0.0158\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0154 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0137 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0137 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "\n",
      "Seed 107, Fold 4\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5749 - logloss: 0.5723 - val_loss: 0.2349 - val_logloss: 0.2349\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1108 - logloss: 0.1103 - val_loss: 0.0475 - val_logloss: 0.0475\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0360 - logloss: 0.0359 - val_loss: 0.0276 - val_logloss: 0.0276\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0258 - logloss: 0.0257 - val_loss: 0.0227 - val_logloss: 0.0227\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0228 - logloss: 0.0227 - val_loss: 0.0207 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0208 - logloss: 0.0207 - val_loss: 0.0192 - val_logloss: 0.0192\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0196 - val_loss: 0.0186 - val_logloss: 0.0186\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0190 - logloss: 0.0189 - val_loss: 0.0179 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0171 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0175 - val_loss: 0.0168 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0165 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 107, Fold 5\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5721 - logloss: 0.5697 - val_loss: 0.2470 - val_logloss: 0.2470\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1094 - logloss: 0.1088 - val_loss: 0.0489 - val_logloss: 0.0489\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0360 - logloss: 0.0358 - val_loss: 0.0279 - val_logloss: 0.0278\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0261 - val_loss: 0.0227 - val_logloss: 0.0227\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0223 - val_loss: 0.0205 - val_logloss: 0.0204\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0194 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0185 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0181 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 24/35\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0147 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "\n",
      "Seed 107, Fold 6\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5733 - logloss: 0.5707 - val_loss: 0.2517 - val_logloss: 0.2517\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1108 - logloss: 0.1102 - val_loss: 0.0468 - val_logloss: 0.0468\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0364 - logloss: 0.0362 - val_loss: 0.0289 - val_logloss: 0.0289\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0258 - logloss: 0.0257 - val_loss: 0.0229 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0209 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0205 - logloss: 0.0204 - val_loss: 0.0192 - val_logloss: 0.0192\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0189 - val_logloss: 0.0188\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0186 - val_loss: 0.0183 - val_logloss: 0.0182\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0175 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0169 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0166 - val_logloss: 0.0165\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0161 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0155 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0127 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "\n",
      "Seed 228, Fold 0\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5717 - logloss: 0.5692 - val_loss: 0.2620 - val_logloss: 0.2620\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1103 - logloss: 0.1098 - val_loss: 0.0460 - val_logloss: 0.0460\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0363 - logloss: 0.0362 - val_loss: 0.0276 - val_logloss: 0.0276\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0256 - logloss: 0.0255 - val_loss: 0.0227 - val_logloss: 0.0227\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0223 - val_loss: 0.0208 - val_logloss: 0.0208\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0195 - logloss: 0.0194 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0167 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0131 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "\n",
      "Seed 228, Fold 1\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5747 - logloss: 0.5721 - val_loss: 0.2438 - val_logloss: 0.2438\n",
      "Epoch 2/35\n",
      "107/107 - 2s - loss: 0.1122 - logloss: 0.1117 - val_loss: 0.0494 - val_logloss: 0.0493\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0277 - val_logloss: 0.0277\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0261 - logloss: 0.0260 - val_loss: 0.0230 - val_logloss: 0.0230\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0227 - logloss: 0.0226 - val_loss: 0.0210 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0208 - logloss: 0.0207 - val_loss: 0.0191 - val_logloss: 0.0191\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0183 - val_logloss: 0.0183\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0188 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0182 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0166 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0169 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0167 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0161 - val_logloss: 0.0161\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0146 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0132 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 228, Fold 2\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5743 - logloss: 0.5718 - val_loss: 0.2396 - val_logloss: 0.2396\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1120 - logloss: 0.1115 - val_loss: 0.0511 - val_logloss: 0.0511\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0370 - logloss: 0.0369 - val_loss: 0.0278 - val_logloss: 0.0279\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0258 - logloss: 0.0257 - val_loss: 0.0234 - val_logloss: 0.0234\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0224 - val_loss: 0.0207 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0185 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0188 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0181 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0169 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0142 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0126 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "\n",
      "Seed 228, Fold 3\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5745 - logloss: 0.5720 - val_loss: 0.2788 - val_logloss: 0.2788\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1118 - logloss: 0.1113 - val_loss: 0.0501 - val_logloss: 0.0501\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0372 - logloss: 0.0371 - val_loss: 0.0285 - val_logloss: 0.0285\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0261 - logloss: 0.0260 - val_loss: 0.0228 - val_logloss: 0.0228\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0227 - logloss: 0.0226 - val_loss: 0.0209 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0201 - val_logloss: 0.0200\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0196 - val_loss: 0.0186 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0173 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0178 - logloss: 0.0178 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0174 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0169 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0158 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0137 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 228, Fold 4\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5777 - logloss: 0.5751 - val_loss: 0.2594 - val_logloss: 0.2594\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1131 - logloss: 0.1126 - val_loss: 0.0460 - val_logloss: 0.0460\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0361 - logloss: 0.0360 - val_loss: 0.0294 - val_logloss: 0.0294\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0261 - logloss: 0.0260 - val_loss: 0.0230 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0223 - val_loss: 0.0203 - val_logloss: 0.0203\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0207 - val_loss: 0.0193 - val_logloss: 0.0191\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0183 - val_logloss: 0.0182\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0178 - val_logloss: 0.0177\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0180 - val_loss: 0.0174 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0184 - val_logloss: 0.0178\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0164 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0162 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0147 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0137 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "\n",
      "Seed 228, Fold 5\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5701 - logloss: 0.5676 - val_loss: 0.2450 - val_logloss: 0.2450\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1101 - logloss: 0.1095 - val_loss: 0.0469 - val_logloss: 0.0469\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0371 - logloss: 0.0369 - val_loss: 0.0282 - val_logloss: 0.0282\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0258 - logloss: 0.0257 - val_loss: 0.0235 - val_logloss: 0.0235\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0210 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0210 - logloss: 0.0209 - val_loss: 0.0195 - val_logloss: 0.0195\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0196 - val_loss: 0.0187 - val_logloss: 0.0187\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0189 - val_loss: 0.0186 - val_logloss: 0.0183\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0176 - val_logloss: 0.0176\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0178 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0171 - val_loss: 0.0168 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0168 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0171 - val_logloss: 0.0169\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0160 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0154 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "\n",
      "Seed 228, Fold 6\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5715 - logloss: 0.5691 - val_loss: 0.2414 - val_logloss: 0.2414\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1106 - logloss: 0.1101 - val_loss: 0.0471 - val_logloss: 0.0471\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0367 - logloss: 0.0365 - val_loss: 0.0289 - val_logloss: 0.0289\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0259 - logloss: 0.0258 - val_loss: 0.0231 - val_logloss: 0.0231\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0223 - val_loss: 0.0206 - val_logloss: 0.0206\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0198 - val_logloss: 0.0198\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0196 - val_loss: 0.0188 - val_logloss: 0.0187\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0181 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0178 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0173 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0158 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0153 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0157\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0134 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0129 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0128 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0127 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "\n",
      "Seed 404, Fold 0\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5739 - logloss: 0.5713 - val_loss: 0.2525 - val_logloss: 0.2525\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1101 - logloss: 0.1096 - val_loss: 0.0474 - val_logloss: 0.0474\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0363 - logloss: 0.0362 - val_loss: 0.0273 - val_logloss: 0.0273\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0257 - logloss: 0.0256 - val_loss: 0.0231 - val_logloss: 0.0231\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0225 - val_loss: 0.0209 - val_logloss: 0.0208\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0192 - val_logloss: 0.0192\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0197 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0186 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0183 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0175 - val_logloss: 0.0174\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0175 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0169 - val_loss: 0.0168 - val_logloss: 0.0166\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "\n",
      "Seed 404, Fold 1\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5736 - logloss: 0.5709 - val_loss: 0.2414 - val_logloss: 0.2414\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1111 - logloss: 0.1106 - val_loss: 0.0516 - val_logloss: 0.0515\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0368 - logloss: 0.0366 - val_loss: 0.0288 - val_logloss: 0.0287\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0257 - logloss: 0.0256 - val_loss: 0.0236 - val_logloss: 0.0235\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0211 - val_logloss: 0.0209\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0207 - val_loss: 0.0196 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0194 - logloss: 0.0194 - val_loss: 0.0186 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0189 - val_loss: 0.0180 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0180 - logloss: 0.0180 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0176 - val_loss: 0.0174 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0169 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0164 - val_loss: 0.0168 - val_logloss: 0.0165\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0150 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0142 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0127 - logloss: 0.0130 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0127 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 404, Fold 2\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5727 - logloss: 0.5702 - val_loss: 0.2572 - val_logloss: 0.2572\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1116 - logloss: 0.1111 - val_loss: 0.0470 - val_logloss: 0.0469\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0364 - logloss: 0.0363 - val_loss: 0.0286 - val_logloss: 0.0286\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0261 - val_loss: 0.0229 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0227 - logloss: 0.0226 - val_loss: 0.0213 - val_logloss: 0.0212\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0197 - val_logloss: 0.0196\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0189 - val_logloss: 0.0188\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0177 - val_logloss: 0.0177\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0159 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0144 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "\n",
      "Seed 404, Fold 3\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5732 - logloss: 0.5706 - val_loss: 0.2520 - val_logloss: 0.2520\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1113 - logloss: 0.1108 - val_loss: 0.0474 - val_logloss: 0.0474\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0364 - logloss: 0.0362 - val_loss: 0.0274 - val_logloss: 0.0274\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0262 - logloss: 0.0261 - val_loss: 0.0235 - val_logloss: 0.0234\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0229 - logloss: 0.0227 - val_loss: 0.0210 - val_logloss: 0.0210\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0208 - logloss: 0.0207 - val_loss: 0.0194 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0194 - logloss: 0.0194 - val_loss: 0.0187 - val_logloss: 0.0186\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0189 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0179 - logloss: 0.0179 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0162 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "\n",
      "Seed 404, Fold 4\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5713 - logloss: 0.5688 - val_loss: 0.2523 - val_logloss: 0.2523\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1094 - logloss: 0.1088 - val_loss: 0.0440 - val_logloss: 0.0440\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0360 - logloss: 0.0359 - val_loss: 0.0277 - val_logloss: 0.0277\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0261 - logloss: 0.0260 - val_loss: 0.0228 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0227 - logloss: 0.0227 - val_loss: 0.0206 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0194 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0195 - logloss: 0.0194 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0186 - logloss: 0.0185 - val_loss: 0.0177 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0172 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0176 - val_loss: 0.0169 - val_logloss: 0.0170\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0161 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0162 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0153 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0150 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0161 - val_logloss: 0.0160\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n",
      "Seed 404, Fold 5\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5719 - logloss: 0.5694 - val_loss: 0.2643 - val_logloss: 0.2643\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1114 - logloss: 0.1107 - val_loss: 0.0485 - val_logloss: 0.0485\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0363 - logloss: 0.0362 - val_loss: 0.0281 - val_logloss: 0.0281\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0262 - val_loss: 0.0235 - val_logloss: 0.0235\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0207 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0206 - val_loss: 0.0192 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0196 - val_loss: 0.0185 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0177 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0180 - val_loss: 0.0173 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0170 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0170 - val_loss: 0.0164 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0169 - val_loss: 0.0162 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0156 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0156 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0147 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "\n",
      "Seed 404, Fold 6\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5753 - logloss: 0.5727 - val_loss: 0.2599 - val_logloss: 0.2599\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1099 - logloss: 0.1093 - val_loss: 0.0458 - val_logloss: 0.0458\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0367 - logloss: 0.0365 - val_loss: 0.0287 - val_logloss: 0.0287\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0262 - val_loss: 0.0226 - val_logloss: 0.0226\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0223 - val_loss: 0.0205 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 2s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0195 - val_logloss: 0.0195\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0196 - val_loss: 0.0185 - val_logloss: 0.0185\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0189 - val_loss: 0.0180 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0175 - val_logloss: 0.0175\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0177 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0173 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0152 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0150 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 23/35\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0142 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 28/35\n",
      "107/107 - 2s - loss: 0.0139 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0140 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "\n",
      "Seed 2208, Fold 0\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5729 - logloss: 0.5705 - val_loss: 0.2435 - val_logloss: 0.2435\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1101 - logloss: 0.1096 - val_loss: 0.0470 - val_logloss: 0.0470\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0362 - logloss: 0.0361 - val_loss: 0.0282 - val_logloss: 0.0282\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0263 - logloss: 0.0261 - val_loss: 0.0233 - val_logloss: 0.0233\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0214 - val_logloss: 0.0214\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0193 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0197 - logloss: 0.0196 - val_loss: 0.0186 - val_logloss: 0.0186\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0186 - logloss: 0.0186 - val_loss: 0.0177 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0181 - logloss: 0.0181 - val_loss: 0.0174 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0171 - val_logloss: 0.0171\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0173 - logloss: 0.0174 - val_loss: 0.0168 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0162 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0163 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0137 - val_loss: 0.0153 - val_logloss: 0.0156\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0127 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "107/107 - 2s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0122 - logloss: 0.0126 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0121 - logloss: 0.0125 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "\n",
      "Seed 2208, Fold 1\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5701 - logloss: 0.5676 - val_loss: 0.2564 - val_logloss: 0.2564\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1111 - logloss: 0.1107 - val_loss: 0.0492 - val_logloss: 0.0491\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0369 - logloss: 0.0368 - val_loss: 0.0277 - val_logloss: 0.0277\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0262 - logloss: 0.0261 - val_loss: 0.0227 - val_logloss: 0.0226\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0227 - logloss: 0.0226 - val_loss: 0.0210 - val_logloss: 0.0210\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0208 - val_loss: 0.0194 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0198 - val_loss: 0.0188 - val_logloss: 0.0187\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0175 - val_logloss: 0.0174\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0178 - logloss: 0.0178 - val_loss: 0.0176 - val_logloss: 0.0174\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0167 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0171 - val_loss: 0.0165 - val_logloss: 0.0165\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0150 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0151 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0150 - val_logloss: 0.0153\n",
      "\n",
      "Seed 2208, Fold 2\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5721 - logloss: 0.5694 - val_loss: 0.2513 - val_logloss: 0.2513\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1114 - logloss: 0.1109 - val_loss: 0.0475 - val_logloss: 0.0475\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0364 - logloss: 0.0363 - val_loss: 0.0275 - val_logloss: 0.0275\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0262 - logloss: 0.0261 - val_loss: 0.0228 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0226 - logloss: 0.0225 - val_loss: 0.0206 - val_logloss: 0.0207\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0207 - val_loss: 0.0194 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0196 - logloss: 0.0195 - val_loss: 0.0187 - val_logloss: 0.0187\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0179 - val_logloss: 0.0179\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0177 - val_logloss: 0.0177\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0178 - logloss: 0.0178 - val_loss: 0.0171 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0168 - val_logloss: 0.0169\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0170 - val_logloss: 0.0170\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0169 - logloss: 0.0169 - val_loss: 0.0165 - val_logloss: 0.0166\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0165 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0160 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0159 - val_logloss: 0.0161\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0155 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0156 - val_logloss: 0.0159\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0155 - val_logloss: 0.0158\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0156 - val_logloss: 0.0159\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0138 - val_loss: 0.0154 - val_logloss: 0.0157\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0135 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0132 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "\n",
      "Seed 2208, Fold 3\n",
      "Epoch 1/35\n",
      "107/107 - 2s - loss: 0.5725 - logloss: 0.5700 - val_loss: 0.2590 - val_logloss: 0.2590\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1105 - logloss: 0.1099 - val_loss: 0.0501 - val_logloss: 0.0501\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0366 - logloss: 0.0366 - val_loss: 0.0279 - val_logloss: 0.0279\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0259 - logloss: 0.0258 - val_loss: 0.0231 - val_logloss: 0.0231\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0225 - logloss: 0.0224 - val_loss: 0.0214 - val_logloss: 0.0212\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0207 - logloss: 0.0206 - val_loss: 0.0194 - val_logloss: 0.0194\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0189 - val_logloss: 0.0188\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0181 - val_logloss: 0.0180\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0182 - val_loss: 0.0176 - val_logloss: 0.0176\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0176 - val_loss: 0.0173 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0175 - val_loss: 0.0179 - val_logloss: 0.0175\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0171 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0168 - val_logloss: 0.0167\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0163 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0160 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0158 - val_loss: 0.0158 - val_logloss: 0.0160\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0154 - logloss: 0.0156 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0152 - logloss: 0.0154 - val_loss: 0.0157 - val_logloss: 0.0159\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0154 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0148 - val_loss: 0.0156 - val_logloss: 0.0157\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0146 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0139 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0128 - logloss: 0.0131 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0126 - logloss: 0.0130 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0125 - logloss: 0.0129 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0123 - logloss: 0.0127 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0124 - logloss: 0.0128 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "\n",
      "Seed 2208, Fold 4\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5737 - logloss: 0.5713 - val_loss: 0.2644 - val_logloss: 0.2644\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1103 - logloss: 0.1098 - val_loss: 0.0481 - val_logloss: 0.0481\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0366 - logloss: 0.0364 - val_loss: 0.0284 - val_logloss: 0.0284\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0262 - logloss: 0.0261 - val_loss: 0.0229 - val_logloss: 0.0229\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0223 - logloss: 0.0222 - val_loss: 0.0206 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0209 - logloss: 0.0210 - val_loss: 0.0194 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0184 - val_logloss: 0.0184\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0187 - logloss: 0.0187 - val_loss: 0.0177 - val_logloss: 0.0177\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0178 - val_logloss: 0.0177\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0177 - logloss: 0.0176 - val_loss: 0.0169 - val_logloss: 0.0169\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0173 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0170 - logloss: 0.0170 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0164 - logloss: 0.0166 - val_loss: 0.0164 - val_logloss: 0.0164\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0164 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0160 - logloss: 0.0161 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0157 - logloss: 0.0159 - val_loss: 0.0156 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0151 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 23/35\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0145 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0144 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0141 - logloss: 0.0143 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0142 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0139 - logloss: 0.0141 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0140 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0140 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0137 - logloss: 0.0139 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "\n",
      "Seed 2208, Fold 5\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5724 - logloss: 0.5698 - val_loss: 0.2442 - val_logloss: 0.2442\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1104 - logloss: 0.1098 - val_loss: 0.0460 - val_logloss: 0.0460\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0365 - logloss: 0.0363 - val_loss: 0.0289 - val_logloss: 0.0288\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0264 - logloss: 0.0263 - val_loss: 0.0230 - val_logloss: 0.0230\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0224 - val_loss: 0.0205 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0195 - logloss: 0.0195 - val_loss: 0.0182 - val_logloss: 0.0182\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0189 - logloss: 0.0188 - val_loss: 0.0176 - val_logloss: 0.0176\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0183 - logloss: 0.0182 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0176 - logloss: 0.0177 - val_loss: 0.0167 - val_logloss: 0.0167\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0172 - logloss: 0.0172 - val_loss: 0.0164 - val_logloss: 0.0165\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0175 - logloss: 0.0176 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0168 - logloss: 0.0169 - val_loss: 0.0162 - val_logloss: 0.0163\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0165 - logloss: 0.0166 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0162 - logloss: 0.0164 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0159 - val_loss: 0.0155 - val_logloss: 0.0156\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0155 - logloss: 0.0157 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0154 - val_logloss: 0.0155\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0153 - val_logloss: 0.0155\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0148 - logloss: 0.0151 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 23/35\n",
      "107/107 - 2s - loss: 0.0146 - logloss: 0.0149 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0144 - logloss: 0.0147 - val_loss: 0.0151 - val_logloss: 0.0153\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0143 - logloss: 0.0145 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 26/35\n",
      "107/107 - 1s - loss: 0.0138 - logloss: 0.0141 - val_loss: 0.0150 - val_logloss: 0.0152\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0136 - logloss: 0.0139 - val_loss: 0.0149 - val_logloss: 0.0152\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 30/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 33/35\n",
      "107/107 - 1s - loss: 0.0132 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0134 - logloss: 0.0137 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0136 - val_loss: 0.0149 - val_logloss: 0.0151\n",
      "\n",
      "Seed 2208, Fold 6\n",
      "Epoch 1/35\n",
      "107/107 - 1s - loss: 0.5723 - logloss: 0.5698 - val_loss: 0.2549 - val_logloss: 0.2549\n",
      "Epoch 2/35\n",
      "107/107 - 1s - loss: 0.1110 - logloss: 0.1105 - val_loss: 0.0466 - val_logloss: 0.0465\n",
      "Epoch 3/35\n",
      "107/107 - 1s - loss: 0.0362 - logloss: 0.0361 - val_loss: 0.0273 - val_logloss: 0.0272\n",
      "Epoch 4/35\n",
      "107/107 - 1s - loss: 0.0259 - logloss: 0.0258 - val_loss: 0.0226 - val_logloss: 0.0226\n",
      "Epoch 5/35\n",
      "107/107 - 1s - loss: 0.0224 - logloss: 0.0223 - val_loss: 0.0205 - val_logloss: 0.0205\n",
      "Epoch 6/35\n",
      "107/107 - 1s - loss: 0.0206 - logloss: 0.0205 - val_loss: 0.0193 - val_logloss: 0.0193\n",
      "Epoch 7/35\n",
      "107/107 - 1s - loss: 0.0198 - logloss: 0.0197 - val_loss: 0.0186 - val_logloss: 0.0186\n",
      "Epoch 8/35\n",
      "107/107 - 1s - loss: 0.0188 - logloss: 0.0187 - val_loss: 0.0178 - val_logloss: 0.0178\n",
      "Epoch 9/35\n",
      "107/107 - 1s - loss: 0.0182 - logloss: 0.0182 - val_loss: 0.0173 - val_logloss: 0.0173\n",
      "Epoch 10/35\n",
      "107/107 - 1s - loss: 0.0178 - logloss: 0.0178 - val_loss: 0.0172 - val_logloss: 0.0172\n",
      "Epoch 11/35\n",
      "107/107 - 1s - loss: 0.0174 - logloss: 0.0174 - val_loss: 0.0167 - val_logloss: 0.0168\n",
      "Epoch 12/35\n",
      "107/107 - 1s - loss: 0.0171 - logloss: 0.0172 - val_loss: 0.0166 - val_logloss: 0.0166\n",
      "Epoch 13/35\n",
      "107/107 - 1s - loss: 0.0167 - logloss: 0.0168 - val_loss: 0.0163 - val_logloss: 0.0164\n",
      "Epoch 14/35\n",
      "107/107 - 1s - loss: 0.0166 - logloss: 0.0167 - val_loss: 0.0161 - val_logloss: 0.0162\n",
      "Epoch 15/35\n",
      "107/107 - 1s - loss: 0.0163 - logloss: 0.0165 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 16/35\n",
      "107/107 - 1s - loss: 0.0161 - logloss: 0.0162 - val_loss: 0.0159 - val_logloss: 0.0160\n",
      "Epoch 17/35\n",
      "107/107 - 1s - loss: 0.0158 - logloss: 0.0160 - val_loss: 0.0158 - val_logloss: 0.0159\n",
      "Epoch 18/35\n",
      "107/107 - 1s - loss: 0.0159 - logloss: 0.0161 - val_loss: 0.0160 - val_logloss: 0.0161\n",
      "Epoch 19/35\n",
      "107/107 - 1s - loss: 0.0156 - logloss: 0.0157 - val_loss: 0.0157 - val_logloss: 0.0158\n",
      "Epoch 20/35\n",
      "107/107 - 1s - loss: 0.0153 - logloss: 0.0155 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 21/35\n",
      "107/107 - 1s - loss: 0.0151 - logloss: 0.0153 - val_loss: 0.0155 - val_logloss: 0.0157\n",
      "Epoch 22/35\n",
      "107/107 - 1s - loss: 0.0149 - logloss: 0.0152 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 23/35\n",
      "107/107 - 1s - loss: 0.0147 - logloss: 0.0149 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 24/35\n",
      "107/107 - 1s - loss: 0.0145 - logloss: 0.0148 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 25/35\n",
      "107/107 - 1s - loss: 0.0142 - logloss: 0.0145 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "107/107 - 1s - loss: 0.0140 - logloss: 0.0143 - val_loss: 0.0154 - val_logloss: 0.0156\n",
      "Epoch 27/35\n",
      "107/107 - 1s - loss: 0.0135 - logloss: 0.0138 - val_loss: 0.0152 - val_logloss: 0.0155\n",
      "Epoch 28/35\n",
      "107/107 - 1s - loss: 0.0133 - logloss: 0.0137 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 29/35\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0135 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "107/107 - 1s - loss: 0.0131 - logloss: 0.0134 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 31/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 32/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 34/35\n",
      "107/107 - 1s - loss: 0.0129 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "Epoch 35/35\n",
      "107/107 - 1s - loss: 0.0130 - logloss: 0.0133 - val_loss: 0.0152 - val_logloss: 0.0154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEEDS = [23, 62, 107, 228, 404, 2208]\n",
    "\n",
    "res = train_targets.copy()\n",
    "ss.loc[:, train_targets.columns] = 0\n",
    "res.loc[:, train_targets.columns] = 0\n",
    "oof = tf.constant(0.0)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    for n, (tr, te) in enumerate(MultilabelStratifiedKFold(n_splits=7, random_state=seed, shuffle=True).split(train_targets, train_targets)):\n",
    "        print(f'Seed {seed}, Fold {n}')\n",
    "    \n",
    "        model = create_model(len(train.columns))\n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n}.hdf5'\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n",
    "        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n",
    "                                     save_weights_only = True, mode = 'min')\n",
    "        model.fit(train.values[tr],\n",
    "                  train_targets.values[tr],\n",
    "                  validation_data=(train.values[te], train_targets.values[te]),\n",
    "                  epochs=35, batch_size=192,\n",
    "                  callbacks=[reduce_lr_loss, cb_checkpt], verbose=2\n",
    "                 )\n",
    "        \n",
    "        model.load_weights(checkpoint_path)\n",
    "        \n",
    "        val_predict = model.predict(train.values[te]) \n",
    "        oof += logloss(tf.constant(train_targets.values[te],dtype=tf.float32),tf.constant(val_predict,dtype=tf.float32))\n",
    "        res.loc[te, train_targets.columns] += val_predict\n",
    "        \n",
    "        test_predict = model.predict(test.values)\n",
    "        ss.loc[:, train_targets.columns] += test_predict\n",
    "        print('')\n",
    "    \n",
    "ss.loc[:, train_targets.columns] /= ((n+1) * len(SEEDS))\n",
    "res.loc[:, train_targets.columns] /=  len(SEEDS)\n",
    "oof /= ((n+1) * len(SEEDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:49:04.658412Z",
     "iopub.status.busy": "2020-10-15T08:49:04.657394Z",
     "iopub.status.idle": "2020-10-15T08:49:05.553291Z",
     "shell.execute_reply": "2020-10-15T08:49:05.554035Z"
    },
    "papermill": {
     "duration": 1.95899,
     "end_time": "2020-10-15T08:49:05.554182",
     "exception": false,
     "start_time": "2020-10-15T08:49:03.595192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Metric: 0.014886022634389168\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF Metric: {metric(train_targets, res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:49:07.711549Z",
     "iopub.status.busy": "2020-10-15T08:49:07.710703Z",
     "iopub.status.idle": "2020-10-15T08:49:07.715689Z",
     "shell.execute_reply": "2020-10-15T08:49:07.716364Z"
    },
    "papermill": {
     "duration": 1.087166,
     "end_time": "2020-10-15T08:49:07.716508",
     "exception": false,
     "start_time": "2020-10-15T08:49:06.629342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.015393173, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:49:10.225425Z",
     "iopub.status.busy": "2020-10-15T08:49:10.224448Z",
     "iopub.status.idle": "2020-10-15T08:49:10.257847Z",
     "shell.execute_reply": "2020-10-15T08:49:10.257289Z"
    },
    "papermill": {
     "duration": 1.270087,
     "end_time": "2020-10-15T08:49:10.257948",
     "exception": false,
     "start_time": "2020-10-15T08:49:08.987861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.loc[test_features['cp_type']=='ctl_vehicle', train_targets.columns] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T08:49:13.429842Z",
     "iopub.status.busy": "2020-10-15T08:49:13.428874Z",
     "iopub.status.idle": "2020-10-15T08:49:15.256819Z",
     "shell.execute_reply": "2020-10-15T08:49:15.255940Z"
    },
    "papermill": {
     "duration": 3.269346,
     "end_time": "2020-10-15T08:49:15.256946",
     "exception": false,
     "start_time": "2020-10-15T08:49:11.987600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "duration": 1657.838012,
   "end_time": "2020-10-15T08:49:20.281979",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-15T08:21:42.443967",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
